import os
import requests
import json
from dotenv import load_dotenv
import time # å¯¼å…¥ time æ¨¡å—ç”¨äºæ›´æ™ºèƒ½çš„ç­‰å¾…

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()
GITHUB_TOKEN = os.getenv("GITHUB_TOKEN")
if not GITHUB_TOKEN:
    raise RuntimeError("è¯·åœ¨ .env ä¸­è®¾ç½® GITHUB_TOKEN")

# é…ç½®ä»“åº“
OWNER = "CherryHQ"
REPO = "cherry-studio"

HEADERS = {
    "Authorization": f"token {GITHUB_TOKEN}",
    "Accept": "application/vnd.github.v3+json"
}

def make_github_request(url, params=None):
    """
    å°è£… GitHub API è¯·æ±‚ï¼Œå¤„ç†é€Ÿç‡é™åˆ¶ã€‚
    """
    while True:
        resp = requests.get(url, headers=HEADERS, params=params)

        # æ£€æŸ¥é€Ÿç‡é™åˆ¶ä¿¡æ¯
        rate_limit_remaining = int(resp.headers.get('X-RateLimit-Remaining', 1))
        rate_limit_reset = int(resp.headers.get('X-RateLimit-Reset', time.time()))

        if resp.status_code == 403 and rate_limit_remaining == 0:
            # è¾¾åˆ°é€Ÿç‡é™åˆ¶ï¼Œè®¡ç®—éœ€è¦ç­‰å¾…çš„æ—¶é—´
            sleep_duration = max(0, rate_limit_reset - time.time()) + 5 # é¢å¤–åŠ 5ç§’ï¼Œç¡®ä¿é‡ç½®
            print(f"\nâš ï¸ **è¾¾åˆ° GitHub API é€Ÿç‡é™åˆ¶ï¼** å‰©ä½™è¯·æ±‚: {rate_limit_remaining}ã€‚")
            print(f"ç­‰å¾… {sleep_duration:.0f} ç§’åé‡è¯•... (ç›´åˆ° {time.ctime(rate_limit_reset)})")
            time.sleep(sleep_duration)
            continue # ç­‰å¾…ç»“æŸåé‡æ–°å°è¯•è¯·æ±‚

        resp.raise_for_status() # å¯¹é 2xx çŠ¶æ€ç æŠ›å‡ºå¼‚å¸¸
        return resp

### å¯é…ç½®èµ·å§‹æ—¥æœŸå’ŒissuesçŠ¶æ€
def fetch_all_issues():
    issues = []
    page = 1
    print(f"ğŸš€ å¼€å§‹ä»ä»“åº“ '{OWNER}/{REPO}' è·å–æ‰€æœ‰ Issues...")
    while True:
        url = f"https://api.github.com/repos/{OWNER}/{REPO}/issues"
        params = {
            "state": "all",
            "per_page": 100,
            "page": page
        }
        resp = make_github_request(url, params=params)
        batch = resp.json()

        if not batch:
            print(f"âœ¨ å·²è·å–æ‰€æœ‰ Issues (å…± {len(issues)} ä¸ª)ã€‚")
            break
        issues.extend(batch)
        print(f"ğŸ“¥ å·²è·å–ç¬¬ {page} é¡µ Issuesï¼Œå½“å‰æ€»æ•°: {len(issues)}")
        page += 1
        time.sleep(0.5) # æ¯æ¬¡è¯·æ±‚åç¨å¾®æš‚åœï¼Œé¿å…ä¸å¿…è¦çš„é€Ÿç‡é™åˆ¶

    return issues

def fetch_comments(comments_url, issue_number):
    comments = []
    page = 1
    # print(f"    ğŸ’¬ æ­£åœ¨è·å– Issue #{issue_number} çš„è¯„è®º...")
    while True:
        params = {
            "per_page": 100,
            "page": page
        }
        resp = make_github_request(comments_url, params=params)
        batch = resp.json()

        if not batch:
            # print(f"    âœ… Issue #{issue_number} è¯„è®ºè·å–å®Œæˆã€‚")
            break
        comments.extend(batch)
        # print(f"    -> å·²è·å– Issue #{issue_number} ç¬¬ {page} é¡µè¯„è®ºï¼Œå½“å‰æ•°é‡: {len(comments)}")
        page += 1
        time.sleep(0.2) # è¯„è®ºè¯·æ±‚å¯ä»¥ç¨å¾®å¿«ä¸€ç‚¹ï¼Œä½†ä»éœ€ç­‰å¾…

    return comments

def main():
    os.makedirs("issues", exist_ok=True)
    raw_issues = fetch_all_issues() # è·å–æ‰€æœ‰ issue çš„åˆ—è¡¨

    total_issues_to_process = 0
    # å…ˆè®¡ç®—éœ€è¦å¤„ç†ï¼ˆä¸‹è½½ï¼‰çš„å®é™… issue æ•°é‡ï¼Œä»¥ä¾¿æ˜¾ç¤ºå‡†ç¡®è¿›åº¦
    for issue in raw_issues:
        if "pull_request" not in issue: # æ’é™¤ Pull Request
            issue_file = f"issues/{issue['number']}.json"
            if not os.path.exists(issue_file):
                total_issues_to_process += 1

    processed_count = 0
    print(f"\nğŸ“‚ å‡†å¤‡å¤„ç† {len(raw_issues)} ä¸ª Issues (å…¶ä¸­çº¦ {total_issues_to_process} ä¸ªéœ€è¦ä¸‹è½½/æ›´æ–°)...")

    for i, issue in enumerate(raw_issues):
        if "pull_request" in issue:
            # print(f"--- è·³è¿‡ Pull Request #{issue['number']}")
            continue

        issue_number = issue['number']
        issue_file = f"issues/{issue_number}.json"

        if os.path.exists(issue_file):
            print(f"â© {i+1}/{len(raw_issues)} - è·³è¿‡å·²å­˜åœ¨ Issue #{issue_number}")
            continue

        processed_count += 1
        print(f"\n--- â¬‡ï¸ æ­£åœ¨ä¸‹è½½ Issue #{issue_number} ({processed_count}/{total_issues_to_process} - æ€»è¿›åº¦ {i+1}/{len(raw_issues)}) ---")
        print(f"    æ ‡é¢˜: {issue.get('title', 'æ— æ ‡é¢˜')}")

        try:
            item = {
                "number": issue_number,
                "title": issue.get("title"),
                "body": issue.get("body"),
                "user": issue.get("user", {}).get("login"),
                "labels": [l["name"] for l in issue.get("labels", [])],
                "assignees": [a["login"] for a in issue.get("assignees", [])],
                "state": issue.get("state"),
                "created_at": issue.get("created_at"),
                "updated_at": issue.get("updated_at"),
                "comments": fetch_comments(issue["comments_url"], issue_number) # ä¼ é€’ issue_number ç”¨äºåé¦ˆ
            }

            with open(issue_file, "w", encoding="utf-8") as f:
                json.dump(item, f, ensure_ascii=False, indent=2)
            print(f"âœ… æˆåŠŸä¿å­˜ Issue #{issue_number} åˆ° {issue_file}")

        except requests.exceptions.RequestException as e:
            print(f"âŒ ä¸‹è½½ Issue #{issue_number} æ—¶å‘ç”Ÿç½‘ç»œé”™è¯¯: {e}")
            print(f"âš ï¸ è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•ã€‚è¯¥ Issue å·²è·³è¿‡ã€‚")
        except Exception as e:
            print(f"âŒ å¤„ç† Issue #{issue_number} æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
            print(f"âš ï¸ è¯¥ Issue å·²è·³è¿‡ã€‚")

    print(f"\nğŸ‰ æ‰€æœ‰ Issue å¤„ç†å®Œæ¯•ï¼")

if __name__ == "__main__":
    main()